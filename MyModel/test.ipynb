{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "file_path = '../sample_file/q_map_0.txt'\n",
    "matrix = np.loadtxt(file_path)\n",
    "matrix = matrix.reshape(1,1,128,128)\n",
    "matrix = torch.tensor(matrix)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax2d(tensor):\n",
    "  n = tensor.size(0)\n",
    "  d = tensor.size(2)\n",
    "  m = tensor.view(n, -1).argmax(1)\n",
    "  return torch.cat(((m / d).view(-1, 1), (m % d).view(-1, 1)), dim=1)\n",
    "\n",
    "argmax2d(matrix)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_matrix = matrix.clone()\n",
    "for i in range(100):\n",
    "    max_index = argmax2d(copy_matrix)[0].long()\n",
    "    print(max_index, copy_matrix[0][0][max_index[0]][max_index[1]])\n",
    "    copy_matrix[0][0][max_index[0]][max_index[1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def argmax2d(tensor):\n",
    "    n = tensor.size(0)\n",
    "    d = tensor.size(2)\n",
    "    m = tensor.view(n, -1).argmax(1)\n",
    "    return torch.cat(((m / d).view(-1, 1), (m % d).view(-1, 1)), dim=1)\n",
    "\n",
    "def set_center_region(submatrix, n, value):\n",
    "    # 获取中心区域的边界\n",
    "    min_row = submatrix.shape[0] // 2 - n // 2\n",
    "    max_row = min_row + n\n",
    "    min_col = submatrix.shape[1] // 2 - n // 2\n",
    "    max_col = min_col + n\n",
    "\n",
    "    # 将中心区域的值设置为指定值\n",
    "    submatrix[min_row:max_row, min_col:max_col] = value\n",
    "    return submatrix\n",
    "\n",
    "\n",
    "def find_second_max(matrix, center, neighborhood_size=20, min_distance=10):\n",
    "\n",
    "    a, b = center\n",
    "\n",
    "    # 定义邻域的边界\n",
    "    min_row = max(0, a - neighborhood_size // 2)\n",
    "    max_row = min(matrix.shape[0], a + neighborhood_size // 2 + 1)\n",
    "    min_col = max(0, b - neighborhood_size // 2)\n",
    "    max_col = min(matrix.shape[1], b + neighborhood_size // 2 + 1)\n",
    "\n",
    "    # 在邻域内找到次最大值的坐标\n",
    "    submatrix = matrix[min_row:max_row, min_col:max_col]\n",
    "    submatrix = set_center_region(submatrix, min_distance, 0)\n",
    "    flattened_indices = np.argsort(submatrix, axis=None)  # 将邻域展平后的索引\n",
    "    second_max_index = np.unravel_index(flattened_indices[-2], submatrix.shape)\n",
    "\n",
    "    # 转换为全局坐标\n",
    "    second_max_coord = (a - neighborhood_size // 2 + second_max_index[0],\n",
    "                        b - neighborhood_size // 2 + second_max_index[1])\n",
    "\n",
    "    return second_max_coord\n",
    "\n",
    "file_path = '../sample_file/q_map_1.txt'\n",
    "matrix = np.loadtxt(file_path)\n",
    "matrix = torch.tensor(matrix)\n",
    "\n",
    "# 找到最大值的坐标\n",
    "max_coords = argmax2d(matrix.reshape(1,1,128,128)).long()[0]\n",
    "\n",
    "# 找到次最大值的坐标\n",
    "second_max_coords = find_second_max(matrix, max_coords)\n",
    "\n",
    "print(\"最大值坐标:\", max_coords)\n",
    "print(\"次最大值坐标:\", second_max_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义一个字典来存储每个 action 的累计 reward 和计数器\n",
    "action_rewards = {}\n",
    "\n",
    "# 打开文件并逐行读取\n",
    "with open(\"../temp/object_attacked_position.txt\") as file:\n",
    "    for line in file:\n",
    "        # 解析每一行，提取出 action 和对应的 reward\n",
    "        values = [float(match) for match in re.findall(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?|\\d+', line)]\n",
    "        action = tuple(values[7:11])  # 提取 action，这里假设 action 是一个由四个元素组成的元组\n",
    "        reward = values[-1]  # 提取 reward\n",
    "\n",
    "        # 更新字典中对应 action 的累计 reward 和计数器\n",
    "        if action in action_rewards:\n",
    "            action_rewards[action]['total_reward'] += reward\n",
    "            action_rewards[action]['count'] += 1\n",
    "        else:\n",
    "            action_rewards[action] = {'total_reward': reward, 'count': 1}\n",
    "\n",
    "# 计算每个 action 的平均 reward\n",
    "average_rewards = {}\n",
    "for action, reward_info in action_rewards.items():\n",
    "    average_reward = reward_info['total_reward'] / reward_info['count']\n",
    "    average_rewards[action] = average_reward\n",
    "\n",
    "# 提取每个动作的x和y坐标\n",
    "x_coords = [action[0] for action in average_rewards.keys()]\n",
    "y_coords = [action[1] for action in average_rewards.keys()]\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(x_coords, y_coords, s=30, c=list(average_rewards.values()), cmap='viridis')\n",
    "plt.colorbar(label='Average Reward')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.title('Average Reward for Each Action')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个字典来存储每个 action 的累计 reward 和计数器\n",
    "action_rewards = {}\n",
    "\n",
    "# 打开文件并逐行读取\n",
    "with open(\"../temp/object_attacked_position.txt\") as file:\n",
    "    for line in file:\n",
    "        # 解析每一行，提取出 action 和对应的 reward\n",
    "        values = [float(match) for match in re.findall(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?|\\d+', line)]\n",
    "        action = tuple(values[7:11])  # 提取 action，这里假设 action 是一个由四个元素组成的元组\n",
    "        reward = values[-1]  # 提取 reward\n",
    "\n",
    "        # 更新字典中对应 action 的累计 reward 和计数器\n",
    "        if action in action_rewards:\n",
    "            action_rewards[action]['total_reward'] += reward\n",
    "            action_rewards[action]['count'] += 1\n",
    "        else:\n",
    "            action_rewards[action] = {'total_reward': reward, 'count': 1}\n",
    "\n",
    "# 计算每个 action 的平均 reward\n",
    "average_rewards = {}\n",
    "for action, reward_info in action_rewards.items():\n",
    "    average_reward = reward_info['total_reward'] / reward_info['count']\n",
    "    average_rewards[action] = average_reward\n",
    "\n",
    "# 提取每个动作的平均奖励值\n",
    "average_rewards_values = list(average_rewards.values())\n",
    "\n",
    "# 划分平均奖励区间\n",
    "num_bins = 10\n",
    "bins = np.linspace(min(average_rewards_values), max(average_rewards_values), num_bins + 1)\n",
    "\n",
    "# 统计每个区间内动作的数量\n",
    "action_counts = {i: 0 for i in range(num_bins)}\n",
    "for reward in average_rewards_values:\n",
    "    for i in range(num_bins):\n",
    "        if bins[i] <= reward < bins[i+1]:\n",
    "            action_counts[i] += 1\n",
    "            break\n",
    "\n",
    "# 绘制柱状图\n",
    "plt.bar(range(num_bins), action_counts.values(), align='center', alpha=0.5)\n",
    "plt.xticks(range(num_bins), [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(num_bins)])\n",
    "plt.xlabel('Average Reward Range')\n",
    "plt.ylabel('Number of Actions')\n",
    "plt.title('Number of Actions in Each Average Reward Range')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4,4)\n",
    "torch.argmax(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no CUDA device found, running on CPU\n",
      "torch.Size([1, 1, 128, 128]) torch.Size([1, 16]) torch.Size([1, 3]) torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6880, 860)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tensor_paths, device):\n",
    "        self.tensor_paths = tensor_paths\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tensor_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tensor_path = self.tensor_paths[idx]\n",
    "        q_value_map, q2_output, action, reward = load_tensor(tensor_path, self.device)\n",
    "        return q_value_map, q2_output, action, reward\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input1_channels, input2_size, input3_size, hidden_size, output_size):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        # Input1的处理\n",
    "        self.conv1 = nn.Conv2d(input1_channels, 4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(16384, 128)\n",
    "        self.fc2 = nn.Linear(128, hidden_size)\n",
    "\n",
    "        # Input2的处理\n",
    "        self.fc3 = nn.Linear(input2_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Input3的处理\n",
    "        self.fc5 = nn.Linear(input3_size, hidden_size)\n",
    "        self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_size * 3, output_size)\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "        # Input1的处理\n",
    "        print(input1.shape)\n",
    "        x1 = torch.relu(self.conv1(input1))\n",
    "        x1 = torch.relu(self.conv2(x1))\n",
    "        x1 = torch.relu(self.conv3(x1))\n",
    "        x1 = self.maxpooling(x1)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        print(x1.shape)\n",
    "        x1 = torch.relu(self.fc1(x1))\n",
    "        x1 = torch.relu(self.fc2(x1))\n",
    "\n",
    "        # Input2的处理\n",
    "        x2 = torch.relu(self.fc3(input2))\n",
    "        x2 = torch.relu(self.fc4(x2))\n",
    "\n",
    "        # Input3的处理\n",
    "        x3 = torch.relu(self.fc5(input3))\n",
    "        x3 = torch.relu(self.fc6(x3))\n",
    "\n",
    "        # 将三个输入连接起来\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "\n",
    "        # 输出层\n",
    "        output = self.output_layer(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def generate_path_list():\n",
    "    path_list = [f\"../dataset/{i}_{j}.pt\" for i in range(86) for j in range(100)]\n",
    "    return path_list\n",
    "\n",
    "def load_tensor(tensor_path, device):\n",
    "    tensor = torch.load(tensor_path, map_location=device).detach()\n",
    "    q_value_map = tensor[:128*128].reshape(1,128,128)\n",
    "    q2_output = tensor[128*128:-4]\n",
    "    action = tensor[-4:-1]\n",
    "    reward = tensor[-1:]\n",
    "    return q_value_map, q2_output, action, reward\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_random_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device('cuda')\n",
    "    print(\"found CUDA device\")\n",
    "else:\n",
    "    # raise ValueError(\"cannot run on cpu device\")\n",
    "    device_name = torch.device('cpu')\n",
    "    print(\"Warning: no CUDA device found, running on CPU\")\n",
    "    \n",
    "set_random_seed(42)\n",
    "data_path_list = generate_path_list()\n",
    "data_num = len(data_path_list)\n",
    "random.shuffle(data_path_list)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(data_path_list))\n",
    "eval_size = int(0.1 * len(data_path_list))\n",
    "test_size = len(data_path_list) - train_size - eval_size\n",
    "\n",
    "train_dataset = CustomDataset(data_path_list[:train_size], device_name)\n",
    "eval_dataset = CustomDataset(data_path_list[train_size:train_size+eval_size], device_name)\n",
    "test_dataset = CustomDataset(data_path_list[train_size+eval_size:], device_name)\n",
    "\n",
    "input1_channels = 1\n",
    "input2_size = 16\n",
    "input3_size = 3\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "MyModel = CustomModel(input1_channels, input2_size, input3_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(MyModel.parameters(), lr=0.001)\n",
    "\n",
    "for a,b,c,d in train_loader:\n",
    "    print(a.shape,b.shape,c.shape,d.shape)\n",
    "    break\n",
    "\n",
    "len(train_dataset), len(eval_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Training:   0%|          | 0/6880 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 16384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 16384])\n",
      "Epoch 1/25, Average Train Loss: 0.0001, Average Eval Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "log_train_loss = []\n",
    "log_eval_loss = []\n",
    "eval_interval = 5\n",
    "for e in range(1):\n",
    "    \n",
    "    MyModel.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f'Epoch {e+1}/{num_epochs}, Training')\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        q_value_map, q2_output, action, reward = data\n",
    "        output = MyModel(q_value_map, q2_output, action)\n",
    "        loss = criterion(output, reward)\n",
    "        log_train_loss.append(loss.detach().item())\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    \n",
    "    MyModel.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_bar = tqdm(eval_loader, desc=f'Epoch {e+1}/{num_epochs}, Evaluating')\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(eval_loader):\n",
    "            q_value_map, q2_output, action, reward = data\n",
    "            output = MyModel(q_value_map, q2_output, action)\n",
    "            loss = criterion(output, reward)\n",
    "            log_eval_loss.append(loss.detach().item())\n",
    "            eval_loss += loss.item()\n",
    "            break\n",
    "\n",
    "    avg_eval_loss = eval_loss / len(eval_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch {e+1}/{num_epochs}, Average Train Loss: {avg_train_loss:.4f}, Average Eval Loss: {avg_eval_loss:.4f}')\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    k = i*0.5\n",
    "    \n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "input = torch.tensor([-8.], requires_grad=True)\n",
    "target = torch.tensor([1.])\n",
    "\n",
    "criterion(input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_input = torch.sigmoid(input)\n",
    "sig_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100., grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_criterion = nn.BCELoss()\n",
    "_criterion(sig_input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"action.txt\", 'r') as file:\n",
    "    line_cnt = 0\n",
    "    sr = 1\n",
    "    data = []\n",
    "    data_dict = {}\n",
    "    for line in file:\n",
    "        numbers = re.findall(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?|\\d+', line)\n",
    "        numeric = [float(num) if '.' in num else int(num) for num in numbers]\n",
    "        line_cnt += 1\n",
    "        if line_cnt == 100:\n",
    "            line_cnt = 0\n",
    "            reward = numeric[-2:-1]\n",
    "            print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bullet37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
